{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:118: UserWarning:\n",
      "\n",
      "CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 1024, 1]),\n",
       " torch.Size([16, 1, 1024, 3]),\n",
       " torch.Size([16, 6, 1024, 3]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config.cfg_algorithm import CFG_MODEL\n",
    "from config.cfg_general import CFG_GENERAL\n",
    "from config.cfg_dataset import CFG_DATASET\n",
    "import os\n",
    "from runner.builder import build_model\n",
    "from data.data_loader import build_dataset\n",
    "from utils.__init__ import config_md5\n",
    "import torch\n",
    "\n",
    "data = [\"PEMS08\",\"T-Drive\",\"CHIBike\",\"NYCTaxi\"][1]\n",
    "algo = \"STID\"\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "epochs = 200\n",
    "val_interval = 1\n",
    "out_dir = \"./checkpoints\"\n",
    "\n",
    "\n",
    "model_args = CFG_MODEL[algo](data, CFG_DATASET[data][\"NUM_NODES\"],\n",
    "                        CFG_GENERAL.DATASET.HISTORY_SEQ_LEN,\n",
    "                        CFG_GENERAL.DATASET.FUTURE_SEQ_LEN,\n",
    "                        not CFG_GENERAL.DATASET.NORM_EACH_CHANNEL,\n",
    "                        CFG_DATASET[data].get(\"STEPS_PER_DAY\",None))\n",
    "\n",
    "md5 = config_md5(CFG_GENERAL, CFG_DATASET[data], model_args)\n",
    "ckpt_save_dir = os.path.join(out_dir, \"_\".join([data, algo, str(epochs)]),md5)\n",
    "if not os.path.isdir(ckpt_save_dir):\n",
    "    os.makedirs(ckpt_save_dir)\n",
    "\n",
    "models = build_model(CFG_GENERAL, model_args)\n",
    "datasets = build_dataset(CFG_GENERAL, CFG_DATASET[data])\n",
    "future_data, history_data = next(iter(datasets[\"train\"]))\n",
    "future_data, history_data = future_data.to(device), history_data.to(device)\n",
    "\n",
    "model = models[\"model\"].to(device)\n",
    "out = model(history_data,history_data,0,0,False)\n",
    "out.shape,future_data.shape, history_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 08:50:20,087 - NYCTaxi_STDCN_200 - INFO - start test\n",
      "100%|██████████| 219/219 [00:02<00:00, 96.65it/s]\n",
      "2024-09-02 08:50:22,357 - NYCTaxi_STDCN_200 - INFO - Result : [test_time: 2.27 (s), test_MAE: 14.247, test_MAPE: 14.131, test_RMSE: 22.690]\n"
     ]
    }
   ],
   "source": [
    "from utils.checkpoint import resume_model\n",
    "from runner.builder import build_meter\n",
    "from utils.logger import init_logger\n",
    "from utils.meter_pool import MeterPool\n",
    "import time\n",
    "from data.transform import re_standard_transform\n",
    "from tqdm import tqdm\n",
    "from utils.metrics import masked_mae, masked_mape, masked_rmse\n",
    "import numpy as np\n",
    "\n",
    "logger = init_logger(f\"{data}_{algo}_{epochs}\",ckpt_save_dir)\n",
    "ckpt_path = f'{algo}_{data}_best_val_MAE.pt'\n",
    "checkpoint_dict = resume_model(ckpt_save_dir,ckpt_path)\n",
    "models[\"model\"].load_state_dict(checkpoint_dict['model_state_dict'], strict=True)\n",
    "logger.info('start test')\n",
    "models[\"model\"].eval()\n",
    "mode = \"test\"\n",
    "epoch = 0\n",
    "metrics = CFG_GENERAL.METRICS\n",
    "tensbd = None\n",
    "\n",
    "\n",
    "forward_features = models[\"forward_features\"]\n",
    "target_features = models[\"target_features\"]\n",
    "data_loader = datasets[mode]\n",
    "scaler = datasets[\"scaler\"]\n",
    "\n",
    "model = models[\"model\"]\n",
    "meters = MeterPool()\n",
    "build_meter(meters,metrics,mode)\n",
    "\n",
    "\n",
    "if mode==\"test\":\n",
    "    reals = []\n",
    "    preds = []\n",
    "\n",
    "test_start_time = time.time()\n",
    "results = {k:[] for k in metrics.keys()}\n",
    "for (future_data, history_data) in tqdm(data_loader):\n",
    "    history_data = history_data.to(device)\n",
    "    future_data = future_data.to(device)\n",
    "        \n",
    "    history_data = history_data[:,:,:,forward_features]\n",
    "    future_data_4_dec = future_data[:,:,:,forward_features]\n",
    "    prediction_data = model(history_data=history_data, future_data=future_data_4_dec, batch_seen=1, epoch=None, train=False)\n",
    "    prediction = re_standard_transform(prediction_data[:,:,:,target_features],**scaler[\"args\"])\n",
    "    real_value = re_standard_transform(future_data[:,:,:,target_features],**scaler[\"args\"])\n",
    "\n",
    "    if mode==\"test\":\n",
    "        reals.append(real_value[...,0].detach().cpu())\n",
    "        preds.append(prediction[...,0].detach().cpu())\n",
    "\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        metric_item = metric_func(*[prediction, real_value, datasets['null_val'], datasets['mask_val']])\n",
    "        meters.update(f\"{mode}_{metric_name}\", metric_item.item())\n",
    "        results[metric_name].append(metric_func(*[prediction, real_value, np.nan,5]).item())\n",
    "\n",
    "test_end_time = time.time()\n",
    "meters.update(f\"{mode}_time\", test_end_time - test_start_time)\n",
    "meters.print_meters(logger)\n",
    "meters.plt_meters(epoch,tensbd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.982404467177718\n",
      "16.782948328479783\n",
      "21.42200029277366\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for k in results.keys():\n",
    "    print(np.array(results[k]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
